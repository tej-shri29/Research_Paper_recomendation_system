{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052fc2b7-34bb-473e-b6e1-9d3f3624b55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad1f716-d79e-4aa6-8888-2eec8808621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d21c40-2ebc-47e8-bc56-3c3a3c96e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final_arxiv1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e996e764-788b-4b84-909d-68591a88fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>['cs.CG']</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A limit relation for entropy and channel capac...</td>\n",
       "      <td>['cs.IT']</td>\n",
       "      <td>In a quantum mechanical model, Diosi, Feldma...</td>\n",
       "      <td>I. Csiszar, F. Hiai and D. Petz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>['cs.NE', 'cs.AI']</td>\n",
       "      <td>The intelligent acoustic emission locator is...</td>\n",
       "      <td>T. Kosel and I. Grabec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Intelligent location of simultaneously active ...</td>\n",
       "      <td>['cs.NE', 'cs.AI']</td>\n",
       "      <td>Part I describes an intelligent acoustic emi...</td>\n",
       "      <td>T. Kosel and I. Grabec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship...</td>\n",
       "      <td>['cs.DS']</td>\n",
       "      <td>In this paper, we introduce the on-line Vite...</td>\n",
       "      <td>Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>Inventions on using sound and speech in GUI</td>\n",
       "      <td>['cs.HC']</td>\n",
       "      <td>Voice Recognition (VR) facilitates a human i...</td>\n",
       "      <td>Umakant Mishra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>Why a Global Time is Needed in a Dependable SoS</td>\n",
       "      <td>['cs.DC']</td>\n",
       "      <td>A system-of-systems (SoS) is a large informa...</td>\n",
       "      <td>Hermann Kopetz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>Inventions on Using Colors in Graphical User I...</td>\n",
       "      <td>['cs.HC']</td>\n",
       "      <td>Color is an important aspect of any graphica...</td>\n",
       "      <td>Umakant Mishra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>Inventions on GUI Aesthetics</td>\n",
       "      <td>['cs.HC']</td>\n",
       "      <td>Aesthetics or \"look and feel\" is one of the ...</td>\n",
       "      <td>Umakant Mishra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>Inventions on selecting GUI elements</td>\n",
       "      <td>['cs.HC']</td>\n",
       "      <td>Selecting an object or element is a fundamen...</td>\n",
       "      <td>Umakant Mishra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title         category_id  \\\n",
       "0               Sparsity-certifying Graph Decompositions           ['cs.CG']   \n",
       "1      A limit relation for entropy and channel capac...           ['cs.IT']   \n",
       "2      Intelligent location of simultaneously active ...  ['cs.NE', 'cs.AI']   \n",
       "3      Intelligent location of simultaneously active ...  ['cs.NE', 'cs.AI']   \n",
       "4      On-line Viterbi Algorithm and Its Relationship...           ['cs.DS']   \n",
       "...                                                  ...                 ...   \n",
       "59995        Inventions on using sound and speech in GUI           ['cs.HC']   \n",
       "59996    Why a Global Time is Needed in a Dependable SoS           ['cs.DC']   \n",
       "59997  Inventions on Using Colors in Graphical User I...           ['cs.HC']   \n",
       "59998                       Inventions on GUI Aesthetics           ['cs.HC']   \n",
       "59999               Inventions on selecting GUI elements           ['cs.HC']   \n",
       "\n",
       "                                                abstract  \\\n",
       "0        We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "1        In a quantum mechanical model, Diosi, Feldma...   \n",
       "2        The intelligent acoustic emission locator is...   \n",
       "3        Part I describes an intelligent acoustic emi...   \n",
       "4        In this paper, we introduce the on-line Vite...   \n",
       "...                                                  ...   \n",
       "59995    Voice Recognition (VR) facilitates a human i...   \n",
       "59996    A system-of-systems (SoS) is a large informa...   \n",
       "59997    Color is an important aspect of any graphica...   \n",
       "59998    Aesthetics or \"look and feel\" is one of the ...   \n",
       "59999    Selecting an object or element is a fundamen...   \n",
       "\n",
       "                                                 authors  \n",
       "0                        Ileana Streinu and Louis Theran  \n",
       "1                        I. Csiszar, F. Hiai and D. Petz  \n",
       "2                                 T. Kosel and I. Grabec  \n",
       "3                                 T. Kosel and I. Grabec  \n",
       "4      Rastislav \\v{S}r\\'amek, Bro\\v{n}a Brejov\\'a, T...  \n",
       "...                                                  ...  \n",
       "59995                                     Umakant Mishra  \n",
       "59996                                     Hermann Kopetz  \n",
       "59997                                     Umakant Mishra  \n",
       "59998                                     Umakant Mishra  \n",
       "59999                                     Umakant Mishra  \n",
       "\n",
       "[60000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11d5385-9ebd-467d-bcf0-cdb43c6d1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959e6d55-3321-4bed-a91e-7f416d183744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = pd.read_csv('arxiv_merged_dataframe.csv'/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e264abe-3da5-4948-b712-b14834b04bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_id >> terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ae43c1c-3f3c-43e4-b4a1-77c6fadb1250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'category_id', 'abstract', 'authors'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd44f2b1-9ae5-4ddd-b58e-f58db82ef35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['category_id','abstract','authors'], axis=True ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cea6db0-de56-4866-8412-bfc3bc97b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d7c20c-8941-4a0b-9458-6dcdcc8f7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe992e8e-f3df-47fa-a100-31eb9165e5a0",
   "metadata": {},
   "source": [
    "# Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84b997d8-4342-48cb-a30b-513db88fe4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c4f875-2c86-4f3b-893e-a83487e749da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e8aceff-74a8-4bb5-af0b-4ea9486fa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe8c68c3-befc-4d0d-8bb2-e54ac0a1c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e414b632-3dd7-441f-8d6e-6561db1a2a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 384)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7566444-f0db-4087-91b4-a2730674226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence : Sparsity-certifying Graph Decompositions\n",
      "embedding : 384\n",
      "\n",
      "sentence : A limit relation for entropy and channel capacity per unit cost\n",
      "embedding : 384\n",
      "\n",
      "sentence : Intelligent location of simultaneously active acoustic emission sources:  Part I\n",
      "embedding : 384\n",
      "\n",
      "sentence : Intelligent location of simultaneously active acoustic emission sources:  Part II\n",
      "embedding : 384\n",
      "\n",
      "sentence : On-line Viterbi Algorithm and Its Relationship to Random Walks\n",
      "embedding : 384\n",
      "\n",
      "sentence : Real Options for Project Schedules (ROPS)\n",
      "embedding : 384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "\n",
    "for sentence, embeddings in zip(sentences, embedding):\n",
    "    print(\"sentence :\", sentence)\n",
    "    print(\"embedding :\", len(embeddings))\n",
    "    print(\"\")\n",
    "    if c >= 5:\n",
    "        break\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2560f-adf8-4eaf-b57e-e605f6b42555",
   "metadata": {},
   "source": [
    "# Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "716d2d44-23c3-4718-9298-697645dcd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ccedd4a4-ec55-4363-8957-cfe67e7b161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/embedding.pkl\", 'wb') as f:\n",
    "    pickle.dump(embedding,f)\n",
    "\n",
    "with open(\"models/sentences.pkl\", 'wb') as f:\n",
    "    pickle.dump(sentences,f)\n",
    "\n",
    "with open(\"models/rec_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0af56396-3d02-4c5f-8840-96988d31b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/rec_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0140c-19fd-468a-8912-f4fa3d825a58",
   "metadata": {},
   "source": [
    "# Recommendation for similar papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7f15f1-b73a-4a47-857d-77e4577e2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a27eeaf-8f8a-4e32-8096-d486cdbc5ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pickle.load(open(\"models/embedding.pkl\",'rb'))\n",
    "sentence = pickle.load(open(\"models/sentences.pkl\",'rb'))\n",
    "rec_model = pickle.load(open(\"models/rec_model.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e5ba7c-2991-4591-9e65-52f6bbc8c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "077adc2c-ce61-418a-ab2c-e2d27e5f3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(input_paper):\n",
    "    cosine_score = util.cos_sim(embedding, rec_model.encode(input_paper))\n",
    "    top_similar_papers = torch.topk(cosine_score, dim = 0, k=5, sorted=True)\n",
    "\n",
    "    paper_list = []\n",
    "    for i in top_similar_papers.indices:\n",
    "        paper_list.append(sentences[i.item()])\n",
    "\n",
    "    return paper_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cde8a93b-819e-4c93-98fc-f773fcd75707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function cos_sim in module sentence_transformers.util:\n",
      "\n",
      "cos_sim(a: torch.Tensor, b: torch.Tensor)\n",
      "    Computes the cosine similarity cos_sim(a[i], b[j]) for all i and j.\n",
      "    :return: Matrix with res[i][j]  = cos_sim(a[i], b[j])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(util.cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413af192-8490-4117-ae69-f7900938f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter research paper title :  Attention is all you need\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Focus of Attention for Linear Predictors',\n",
       " 'The dynamic pattern of human attention',\n",
       " 'Attention-Sensitive Alerting',\n",
       " 'Persistence and Success in the Attention Economy',\n",
       " '6th International Symposium on Attention in Cognitive Systems 2013']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_paper = input(\"Enter research paper title : \")\n",
    "\n",
    "recommended_paper = recommendation(input_paper)\n",
    "recommended_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a11e4166-ed2b-4157-9951-ddf2cd33ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.DataFrame(recommended_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93009d11-54ff-4883-bb1e-9af627b89796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = \"Attention is all you need\"\n",
    "# myemb = rec_model.encode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e1bc1fe-a56e-46a1-b87d-9a949d439ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Focus of Attention for Linear Predictors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dynamic pattern of human attention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attention-Sensitive Alerting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Persistence and Success in the Attention Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6th International Symposium on Attention in Co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0           Focus of Attention for Linear Predictors\n",
       "1             The dynamic pattern of human attention\n",
       "2                       Attention-Sensitive Alerting\n",
       "3   Persistence and Success in the Attention Economy\n",
       "4  6th International Symposium on Attention in Co..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e356339-b332-43f9-b897-7a69a3a5bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.cos_sim(embedding, myemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f76533c2-828f-4440-9622-8c89d6dbe1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b3a56b7-7172-41f0-8180-1558466e58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5669001-22bd-4e49-8bee-749f10461bc7",
   "metadata": {},
   "source": [
    "# Data Cleaninig and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee348337-1a6a-4063-a827-402e7d84dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data = pd.read_csv(\"Final_arxiv1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d7b9406-8b8e-41bf-9a42-487ba32dfcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data = arxiv_data[~arxiv_data['title'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0e4290e-de8d-4220-b38e-960f6ce70d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59910, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7aa81e8-017e-466c-847a-6a3ea3945671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arxiv_data['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d893244e-f730-4231-9bf3-f7cf03f51208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n"
     ]
    }
   ],
   "source": [
    "print(sum(arxiv_data['category_id'].value_counts()==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fd32502-172e-4283-9ca3-ab7105d21a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2626\n"
     ]
    }
   ],
   "source": [
    "print(arxiv_data['category_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "903a7b9e-c649-46dd-988f-34e1353280d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data_filtered = arxiv_data.groupby('category_id').filter(lambda x: len(x) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80bf5a95-7a74-405f-bf39-7c1375aa5816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59910, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        arxiv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9298794f-e145-41e1-b588-3c699544164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_data_filtered['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60c98150-c8a1-48a9-8200-37febf575f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_data_filtered['category_id'] = arxiv_data_filtered['category_id'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b7fa6b1-270a-4125-b79f-c95e7d4b4118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['cs.CG']), list(['cs.IT']), list(['cs.NE', 'cs.AI'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data_filtered['category_id'].values[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1261a422-000d-449e-a4a6-5cbb3e4502b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "18cf2637-5ce0-4f62-b623-4468a14f18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e212a817-a4cb-45b0-8797-8d00720b3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab4d3b08-a8a2-43ac-a9ed-83f6f6000752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_columns = arxiv_data['category_id'].apply(literal_eval)\n",
    "# labels = labels_columns.explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "78975619-01a4-408b-9049-50c7708845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "86a0fa8e-9ebc-4571-b4c3-6d8b05be727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_data[arxiv_data['title'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb0652-1762-4a78-8227-d6fa4f6134ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85122faf-03ec-4791-982e-ec6b6bd98fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e88e6-f52a-432d-856b-49669676c6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a0916-f996-4907-8334-f35423d930fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336cfb04-54e6-43bc-b9f6-30648b5b86f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a4642db-888e-4d29-8284-ab3bdff23e51",
   "metadata": {},
   "source": [
    "# Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f806124-3a63-4c61-8577-85281a7c8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(arxiv_data_filtered, test_size=0.1, stratify=arxiv_data_filtered['category_id'].values )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0a013d6-bd93-4b53-8b3f-44c239573688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5853, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34ef0314-4ec5-42f8-ad73-65bcce258046",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = test_df.sample(frac = 0.5)\n",
    "test_df.drop(val_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ff61be0-3bc4-4cf1-b01f-130cbeb4ae2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42180</th>\n",
       "      <td>A Fast Template Based Heuristic For Global Mul...</td>\n",
       "      <td>[cs.CE]</td>\n",
       "      <td>Advances in bio-technology have made availab...</td>\n",
       "      <td>Srikrishnan Divakaran, Arpit Mithal, and Namit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13378</th>\n",
       "      <td>Extension of Wirtinger Calculus in RKH Spaces ...</td>\n",
       "      <td>[cs.LG]</td>\n",
       "      <td>Over the last decade, kernel methods for non...</td>\n",
       "      <td>Pantelis Bouboulis, Sergios Theodoridis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>A Tighter Bound for the Determinization of Vis...</td>\n",
       "      <td>[cs.FL, cs.LO]</td>\n",
       "      <td>Visibly pushdown automata (VPA), introduced ...</td>\n",
       "      <td>Nguyen Van Tang (AIST)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20749</th>\n",
       "      <td>A Coinductive Calculus for Asynchronous Side-e...</td>\n",
       "      <td>[cs.LO]</td>\n",
       "      <td>We present an abstract framework for concurr...</td>\n",
       "      <td>Sergey Goncharov and Lutz Schr\\\"oder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41539</th>\n",
       "      <td>Byzantine Vector Consensus in Complete Graphs</td>\n",
       "      <td>[cs.DC]</td>\n",
       "      <td>Consider a network of n processes each of wh...</td>\n",
       "      <td>Nitin H. Vaidya, Vijay K. Garg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19757</th>\n",
       "      <td>A Note on the Sum of Correlated Gamma Random V...</td>\n",
       "      <td>[cs.IT]</td>\n",
       "      <td>The sum of correlated gamma random variables...</td>\n",
       "      <td>Jose F. Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46323</th>\n",
       "      <td>A Note on Cyclic Codes from APN Functions</td>\n",
       "      <td>[cs.IT]</td>\n",
       "      <td>Cyclic codes, as linear block error-correcti...</td>\n",
       "      <td>Chunming Tang, Yanfeng Qi, Maozhi Xu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46410</th>\n",
       "      <td>Hybrid Optical and Electrical Network Flows Sc...</td>\n",
       "      <td>[cs.NI]</td>\n",
       "      <td>Hybrid intra-data centre networks, with opti...</td>\n",
       "      <td>Ibrahim Kabiru Musa and Stuart Walker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14770</th>\n",
       "      <td>Weighted Automata and Recurrence Equations for...</td>\n",
       "      <td>[cs.FL, cs.DM]</td>\n",
       "      <td>Let $\\mathcal{P}(\\Sigma^*)$ be the semiring ...</td>\n",
       "      <td>Edoardo Carta-Gerardino, Parisa Babaali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21756</th>\n",
       "      <td>Transmission Control of Two-User Slotted ALOHA...</td>\n",
       "      <td>[cs.IT]</td>\n",
       "      <td>In this paper, we consider the problem of ca...</td>\n",
       "      <td>Anthony Fanous and Anthony Ephremides</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2927 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title     category_id  \\\n",
       "42180  A Fast Template Based Heuristic For Global Mul...         [cs.CE]   \n",
       "13378  Extension of Wirtinger Calculus in RKH Spaces ...         [cs.LG]   \n",
       "10061  A Tighter Bound for the Determinization of Vis...  [cs.FL, cs.LO]   \n",
       "20749  A Coinductive Calculus for Asynchronous Side-e...         [cs.LO]   \n",
       "41539      Byzantine Vector Consensus in Complete Graphs         [cs.DC]   \n",
       "...                                                  ...             ...   \n",
       "19757  A Note on the Sum of Correlated Gamma Random V...         [cs.IT]   \n",
       "46323          A Note on Cyclic Codes from APN Functions         [cs.IT]   \n",
       "46410  Hybrid Optical and Electrical Network Flows Sc...         [cs.NI]   \n",
       "14770  Weighted Automata and Recurrence Equations for...  [cs.FL, cs.DM]   \n",
       "21756  Transmission Control of Two-User Slotted ALOHA...         [cs.IT]   \n",
       "\n",
       "                                                abstract  \\\n",
       "42180    Advances in bio-technology have made availab...   \n",
       "13378    Over the last decade, kernel methods for non...   \n",
       "10061    Visibly pushdown automata (VPA), introduced ...   \n",
       "20749    We present an abstract framework for concurr...   \n",
       "41539    Consider a network of n processes each of wh...   \n",
       "...                                                  ...   \n",
       "19757    The sum of correlated gamma random variables...   \n",
       "46323    Cyclic codes, as linear block error-correcti...   \n",
       "46410    Hybrid intra-data centre networks, with opti...   \n",
       "14770    Let $\\mathcal{P}(\\Sigma^*)$ be the semiring ...   \n",
       "21756    In this paper, we consider the problem of ca...   \n",
       "\n",
       "                                                 authors  \n",
       "42180  Srikrishnan Divakaran, Arpit Mithal, and Namit...  \n",
       "13378            Pantelis Bouboulis, Sergios Theodoridis  \n",
       "10061                             Nguyen Van Tang (AIST)  \n",
       "20749               Sergey Goncharov and Lutz Schr\\\"oder  \n",
       "41539                     Nitin H. Vaidya, Vijay K. Garg  \n",
       "...                                                  ...  \n",
       "19757                                      Jose F. Paris  \n",
       "46323               Chunming Tang, Yanfeng Qi, Maozhi Xu  \n",
       "46410              Ibrahim Kabiru Musa and Stuart Walker  \n",
       "14770            Edoardo Carta-Gerardino, Parisa Babaali  \n",
       "21756              Anthony Fanous and Anthony Ephremides  \n",
       "\n",
       "[2927 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a448f9f0-9fea-4d04-8eb8-ba238f9bb312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2926, 4), (2927, 4))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e70f4c15-4986-4ba8-8c11-345f43acd24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52674, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9efdf24-b4b4-4e06-9511-547541074353",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms =  tf.ragged.constant(train_df['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47d4bf9f-5219-432f-8566-e83a0a1376b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lookup = tf.keras.layers.StringLookup(output_mode='multi_hot')\n",
    "lookup.adapt(terms)\n",
    "vocab = lookup.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16c6a0f4-a688-44f1-90a8-4a1196923539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cs.LG']\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(1, 41), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sample_label = train_df['category_id'].iloc[0]\n",
    "print(sample_label)\n",
    "label_binarized = lookup([sample_label])\n",
    "print(label_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "384899f0-97c2-4761-9977-e3c2643348cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen = 150\n",
    "batch_size = 128\n",
    "padding_token = \"<pad>\"\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe['category_id'].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataframe['abstract'].values, label_binarized))\n",
    "    dataset = dataset.shuffle(batch_size*10) if is_train else dataset\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1314334e-b6b4-46d7-ac8a-da57a724bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "val_dataset = make_dataset(val_df, is_train=True)\n",
    "test_dataset = make_dataset(test_df, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3a62799-e40e-45ab-98a8-c0208a94a3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'  Given an undirected graph $G$, the Minimum Sum Coloring problem (MSCP) is to\\nfind a legal assignment of colors (represented by natural numbers) to each\\nvertex of $G$ such that the total sum of the colors assigned to the vertices is\\nminimized. This paper presents a memetic algorithm for MSCP based on a tabu\\nsearch procedure with two neighborhoods and a multi-parent crossover operator.\\nExperiments on a set of 77 well-known DIMACS and COLOR 2002-2004 benchmark\\ninstances show that the proposed algorithm achieves highly competitive results\\nin comparison with five state-of-the-art algorithms. In particular, the\\nproposed algorithm can improve the best known results for 17 instances. We also\\nprovide upper bounds for 18 additional instances for the first time.\\n', shape=(), dtype=string)\n",
      "['cs.DL']\n",
      "tf.Tensor(b\"  Most researchers acknowledge an intrinsic hierarchy in the scholarly journals\\n('journal rank') that they submit their work to, and adjust not only their\\nsubmission but also their reading strategies accordingly. On the other hand,\\nmuch has been written about the negative effects of institutionalizing journal\\nrank as an impact measure. So far, contributions to the debate concerning the\\nlimitations of journal rank as a scientific impact assessment tool have either\\nlacked data, or relied on only a few studies. In this review, we present the\\nmost recent and pertinent data on the consequences of our current scholarly\\ncommunication system with respect to various measures of scientific quality\\n(such as utility/citations, methodological soundness, expert ratings or\\nretractions). These data corroborate previous hypotheses: using journal rank as\\nan assessment tool is bad scientific practice. Moreover, the data lead us to\\nargue that any journal rank (not only the currently-favored Impact Factor)\\nwould have this negative impact. Therefore, we suggest that abandoning journals\\naltogether, in favor of a library-based scholarly communication system, will\\nultimately be necessary. This new system will use modern information technology\\nto vastly improve the filter, sort and discovery functions of the current\\njournal system.\\n\", shape=(), dtype=string)\n",
      "['cs.DL']\n",
      "tf.Tensor(b'  Automatic synthesis of hardware components from declarative specifications is\\nan ambitious endeavor in computer aided design. Existing synthesis algorithms\\nare often implemented with Binary Decision Diagrams (BDDs), inheriting their\\nscalability limitations. Instead of BDDs, we propose several new methods to\\nsynthesize finite-state systems from safety specifications using decision\\nprocedures for the satisfiability of quantified and unquantified Boolean\\nformulas (SAT-, QBF- and EPR-solvers). The presented approaches are based on\\ncomputational learning, templates, or reduction to first-order logic. We also\\npresent an efficient parallelization, and optimizations to utilize reachability\\ninformation and incremental solving. Finally, we compare all methods in an\\nextensive case study. Our new methods outperform BDDs and other existing work\\non some classes of benchmarks, and our parallelization achieves a super-linear\\nspeedup. This is an extended version of [5], featuring an additional appendix.\\n', shape=(), dtype=string)\n",
      "['cs.DL']\n",
      "tf.Tensor(b'  Optimization of energy consumption in future intelligent energy networks (or\\nSmart Grids) will be based on grid-integrated near-real-time communications\\nbetween various grid elements in generation, transmission, distribution and\\nloads. This paper discusses some of the challenges and opportunities of\\ncommunications research in the areas of smart grid and smart metering. In\\nparticular, we focus on some of the key communications challenges for realizing\\ninteroperable and future-proof smart grid/metering networks, smart grid\\nsecurity and privacy, and how some of the existing networking technologies can\\nbe applied to energy management. Finally, we also discuss the coordinated\\nstandardization efforts in Europe to harmonize communications standards and\\nprotocols.\\n', shape=(), dtype=string)\n",
      "['cs.DL']\n",
      "tf.Tensor(b'  There is analyzed a performance of optimal feedback communication systems\\nwith the analog transmitters in the forward channel (AFCS). It is shown that\\nmeasures and limit boundaries of AFCS performance are similar but differ from\\nthose used in digital communications and information theory. The causes of the\\ndifferences are discussed.\\n', shape=(), dtype=string)\n",
      "['cs.DL']\n"
     ]
    }
   ],
   "source": [
    "def invert_multi_hot(encoded_labels):\n",
    "    hot_indices = np.argwhere(encoded_labels==1.0)[...,0]\n",
    "    return np.take(vocab, hot_indices)\n",
    "\n",
    "\n",
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "for i, text in enumerate(text_batch[:5]):\n",
    "    label = label_batch[1].numpy()[None, ...]\n",
    "    print(text)\n",
    "    print(invert_multi_hot(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7bea052-4459-481a-a1a3-637240c20740",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "train_df['abstract'].str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370877bf-9f36-40e8-a7bc-af8efbede20d",
   "metadata": {},
   "source": [
    "# Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14c1386f-13d2-4b07-bf0c-fe695d5a3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = layers.TextVectorization(max_tokens=vocabulary_size, ngrams=2, output_mode='tf_idf')\n",
    "text_vectorizer.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5267d77c-881b-43e9-b5e4-62f962ec7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer_weights = text_vectorizer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67be6997-4b4c-4bb7-a6f5-3303455d0891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([8.539302 , 0.6997619, 0.7040981, ..., 9.773322 , 9.485659 ,\n",
       "        9.773322 ], dtype=float32),\n",
       " array([b'the', b'of', b'a', ..., b'traditional packet',\n",
       "        b'traditional notions', b'traditional noncooperation'],\n",
       "       dtype=object),\n",
       " 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8854bf15-a8fe-430b-ba8c-fc70cd73f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/text_vectorizer_weights.pkl\", 'wb') as f:\n",
    "    pickle.dump(text_vectorizer_weights,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0016ea6a-cb4e-4ec6-ad1b-76030e0c7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "val_dataset = val_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)\n",
    "test_dataset = test_dataset.map(lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto).prefetch(auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202c806-8c13-422b-ba45-9c1689dd2599",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "We are using Multi-Layer perceptron for Subject area prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2768dbc-5cda-4504-a9bb-111757213ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(lookup.vocabulary_size(), activation='sigmoid')   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "136f24ab-8184-4a71-97a1-c5d320de2652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ingle\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c04c63e6-7168-44ea-8d91-9851abba431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9979389-4b39-44a4-827c-008c8ed40cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     train_dataset,\n",
    "#     validation_data=val_dataset, \n",
    "#     epochs=20,\n",
    "#     callbacks=[es]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc31479-0cd1-4d0f-9e10-8330e8604e92",
   "metadata": {},
   "source": [
    "# Save Model and Text Vectorizer\n",
    "Model, Vectorizer and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97e855a4-7561-4927-9934-915bb871f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/model1.h5')\n",
    "\n",
    "save_text_vectorizer_config = text_vectorizer.get_config()\n",
    "with open('models/text_vectorizer_weights.pkl','wb') as f:\n",
    "    pickle.dump(save_text_vectorizer_config, f)\n",
    "\n",
    "with open('models/vocab.pkl', 'wb') as f:\n",
    "    pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a4a95d7-8205-4b38-82fd-b53edc3795b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2f1af-d9aa-4f26-962a-63b79cb69156",
   "metadata": {},
   "source": [
    "# Load Model and Text Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc0646f5-3992-440f-a37d-b53984edbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = keras.models.load_model('models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ab7cb9f-d34e-47ff-9707-f5010e11b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"models/text_vectorizer_config.pkl\", 'rb') as f:\n",
    "    save_text_vectorizer_config = pickle.load(f)\n",
    "\n",
    "load_text_vectorizer = text_vectorizer.from_config(save_text_vectorizer_config)\n",
    "\n",
    "with open(\"models/vocab.pkl\", 'rb') as f:\n",
    "    loaded_vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45e86c1d-e001-43a7-a68a-d818eb163b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Sequential' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/training_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     weighs \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m----> 3\u001b[0m     load_text_vectorizer\u001b[38;5;241m.\u001b[39mset_weights(weighs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:1796\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1794\u001b[0m         expected_num_weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_num_weights \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(weights):\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou called `set_weights(weights)` on layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1799\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a weight list of length \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, but the layer was \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1806\u001b[0m         )\n\u001b[0;32m   1807\u001b[0m     )\n\u001b[0;32m   1809\u001b[0m weight_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Sequential' has no len()"
     ]
    }
   ],
   "source": [
    "with open(\"models/training_model.pkl\", 'rb') as f:\n",
    "    weighs = pickle.load(f)\n",
    "    load_text_vectorizer.set_weights(weighs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9116d13d-8568-4011-a7f3-5f800e66b1eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextVectorization' object has no attribute 'load_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_text_vectorizer\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/training_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TextVectorization' object has no attribute 'load_weights'"
     ]
    }
   ],
   "source": [
    "load_text_vectorizer.load_weights(\"models/training_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3efff-72ba-4dae-b68e-91ed1fea9dd1",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e864f6c3-5d38-4d7b-b707-806d3ff650f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d2a5438a-92ee-4639-9927-f827eae069fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bef80-a468-4f94-99ff-59a465243d09",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "87ab1905-4da9-4543-89d5-87e6efc68694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_multi_hot(encoded_hot):\n",
    "    hot_indeces = np.argwhere(encoded_hot == 1.0)[...,0]\n",
    "    return np.take(loaded_vocab, hot_indeces)\n",
    "\n",
    "def pred_categories(abstract, model, vectorizer, label_lookup):\n",
    "    preprocessed_abstract = vectorizer([abstract])\n",
    "    predictions = model.predict(preprocessed_abstract)\n",
    "    preduicted_labels = label_lookup(np.round(predictions).astype(int)[0])\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b55479e-7d91-4a86-a731-296ee8619825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m new_abstract \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mooooo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m predicted_category \u001b[38;5;241m=\u001b[39m pred_categories(new_abstract, load_model, load_text_vectorizer, invert_multi_hot)\n",
      "Cell \u001b[1;32mIn[78], line 9\u001b[0m, in \u001b[0;36mpred_categories\u001b[1;34m(abstract, model, vectorizer, label_lookup)\u001b[0m\n\u001b[0;32m      7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(preprocessed_abstract)\n\u001b[0;32m      8\u001b[0m preduicted_labels \u001b[38;5;241m=\u001b[39m label_lookup(np\u001b[38;5;241m.\u001b[39mround(predictions)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_labels\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "new_abstract = \"ooooo\"\n",
    "predicted_category = pred_categories(new_abstract, load_model, load_text_vectorizer, invert_multi_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "597c90b8-af88-4452-99d3-ceed3494310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  In some particular cases we give criteria for morphic sequences to be almost\\nperiodic (=uniformly recurrent). Namely, we deal with fixed points of\\nnon-erasing morphisms and with automatic sequences. In both cases a\\npolynomial-time algorithm solving the problem is found. A result more or less\\nsupporting the conjecture of decidability of the general problem is given.\\n'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_data['abstract'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c96004fc-6723-41a3-a604-f0cd962f13b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Exception encountered when calling layer 'string_lookup_11' (type StringLookup).\n\n{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \n\nCall arguments received by layer 'string_lookup_11' (type StringLookup):\n  â€¢ inputs=<tf.RaggedTensor [[b'in', b'some', b'particular', b'cases', b'we', b'give', b'criteria',\n  b'for', b'morphic', b'sequences', b'to', b'be', b'almost', b'periodic',\n  b'uniformly', b'recurrent', b'namely', b'we', b'deal', b'with',\n  b'fixed', b'points', b'of', b'nonerasing', b'morphisms', b'and',\n  b'with', b'automatic', b'sequences', b'in', b'both', b'cases', b'a',\n  b'polynomialtime', b'algorithm', b'solving', b'the', b'problem', b'is',\n  b'found', b'a', b'result', b'more', b'or', b'less', b'supporting',\n  b'the', b'conjecture', b'of', b'decidability', b'of', b'the',\n  b'general', b'problem', b'is', b'given', b'in some', b'some particular',\n  b'particular cases', b'cases we', b'we give', b'give criteria',\n  b'criteria for', b'for morphic', b'morphic sequences', b'sequences to',\n  b'to be', b'be almost', b'almost periodic', b'periodic uniformly',\n  b'uniformly recurrent', b'recurrent namely', b'namely we', b'we deal',\n  b'deal with', b'with fixed', b'fixed points', b'points of',\n  b'of nonerasing', b'nonerasing morphisms', b'morphisms and',\n  b'and with', b'with automatic', b'automatic sequences', b'sequences in',\n  b'in both', b'both cases', b'cases a', b'a polynomialtime',\n  b'polynomialtime algorithm', b'algorithm solving', b'solving the',\n  b'the problem', b'problem is', b'is found', b'found a', b'a result',\n  b'result more', b'more or', b'or less', b'less supporting',\n  b'supporting the', b'the conjecture', b'conjecture of',\n  b'of decidability', b'decidability of', b'of the', b'the general',\n  b'general problem', b'problem is', b'is given']]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m new_abstract \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn some particular cases we give criteria for morphic sequences to be almost\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mperiodic (=uniformly recurrent). Namely, we deal with fixed points of\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mnon-erasing morphisms and with automatic sequences. In both cases a\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mpolynomial-time algorithm solving the problem is found. A result more or less\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124msupporting the conjecture of decidability of the general problem is given.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m predicted_category \u001b[38;5;241m=\u001b[39m pred_categories(new_abstract, load_model, load_text_vectorizer, invert_multi_hot)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Categories:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_category)\n",
      "Cell \u001b[1;32mIn[226], line 6\u001b[0m, in \u001b[0;36mpred_categories\u001b[1;34m(abstract, model, vectorizer, label_lookup)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpred_categories\u001b[39m(abstract, model, vectorizer, label_lookup):\n\u001b[1;32m----> 6\u001b[0m     preprocessed_abstract \u001b[38;5;241m=\u001b[39m vectorizer([abstract])\n\u001b[0;32m      7\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(preprocessed_abstract)\n\u001b[0;32m      8\u001b[0m     preduicted_labels \u001b[38;5;241m=\u001b[39m label_lookup(np\u001b[38;5;241m.\u001b[39mround(predictions)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\forgery\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\index_lookup.py:792\u001b[0m, in \u001b[0;36mIndexLookup._lookup_dense\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    790\u001b[0m     lookups \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros_like(inputs, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_dtype)\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 792\u001b[0m     lookups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlookup_table\u001b[38;5;241m.\u001b[39mlookup(inputs)\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    795\u001b[0m     mask_locations \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mequal(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_key)\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Exception encountered when calling layer 'string_lookup_11' (type StringLookup).\n\n{{function_node __wrapped__LookupTableFindV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Table not initialized. [Op:LookupTableFindV2] name: \n\nCall arguments received by layer 'string_lookup_11' (type StringLookup):\n  â€¢ inputs=<tf.RaggedTensor [[b'in', b'some', b'particular', b'cases', b'we', b'give', b'criteria',\n  b'for', b'morphic', b'sequences', b'to', b'be', b'almost', b'periodic',\n  b'uniformly', b'recurrent', b'namely', b'we', b'deal', b'with',\n  b'fixed', b'points', b'of', b'nonerasing', b'morphisms', b'and',\n  b'with', b'automatic', b'sequences', b'in', b'both', b'cases', b'a',\n  b'polynomialtime', b'algorithm', b'solving', b'the', b'problem', b'is',\n  b'found', b'a', b'result', b'more', b'or', b'less', b'supporting',\n  b'the', b'conjecture', b'of', b'decidability', b'of', b'the',\n  b'general', b'problem', b'is', b'given', b'in some', b'some particular',\n  b'particular cases', b'cases we', b'we give', b'give criteria',\n  b'criteria for', b'for morphic', b'morphic sequences', b'sequences to',\n  b'to be', b'be almost', b'almost periodic', b'periodic uniformly',\n  b'uniformly recurrent', b'recurrent namely', b'namely we', b'we deal',\n  b'deal with', b'with fixed', b'fixed points', b'points of',\n  b'of nonerasing', b'nonerasing morphisms', b'morphisms and',\n  b'and with', b'with automatic', b'automatic sequences', b'sequences in',\n  b'in both', b'both cases', b'cases a', b'a polynomialtime',\n  b'polynomialtime algorithm', b'algorithm solving', b'solving the',\n  b'the problem', b'problem is', b'is found', b'found a', b'a result',\n  b'result more', b'more or', b'or less', b'less supporting',\n  b'supporting the', b'the conjecture', b'conjecture of',\n  b'of decidability', b'decidability of', b'of the', b'the general',\n  b'general problem', b'problem is', b'is given']]>"
     ]
    }
   ],
   "source": [
    "new_abstract = \"In some particular cases we give criteria for morphic sequences to be almost\\nperiodic (=uniformly recurrent). Namely, we deal with fixed points of\\nnon-erasing morphisms and with automatic sequences. In both cases a\\npolynomial-time algorithm solving the problem is found. A result more or less\\nsupporting the conjecture of decidability of the general problem is given.\\n\"\n",
    "\n",
    "predicted_category = pred_categories(new_abstract, load_model, load_text_vectorizer, invert_multi_hot)\n",
    "\n",
    "print(\"Predicted Categories:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f62f4-78ec-47f9-a103-5d083eb8f8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3183c2-c617-4e92-b74b-5c9e1df626ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654b2a6-ef22-4204-a32b-a6ca411df288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
